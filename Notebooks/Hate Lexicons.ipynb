{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = pd.read_csv('Hinglish_Profanity_List.csv', encoding='unicode_escape', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badir</td>\n",
       "      <td>idiot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>badirchand</td>\n",
       "      <td>idiot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bakland</td>\n",
       "      <td>idiot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bhadva</td>\n",
       "      <td>pimp</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bhootnika</td>\n",
       "      <td>son of a witch</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0               1  2\n",
       "0       badir           idiot  1\n",
       "1  badirchand           idiot  1\n",
       "2     bakland           idiot  1\n",
       "3      bhadva            pimp  2\n",
       "4   bhootnika  son of a witch  3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_lexicons = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in lex[0]:\n",
    "    hate_lexicons.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hate_lexicons = set(hate_lexicons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hate_lexicons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emb</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1615850780</td>\n",
       "      <td>929479629840281601</td>\n",
       "      <td>[ 0.00447152 -0.00207724 -0.00693714 -0.005786...</td>\n",
       "      <td>I am a young person and I am quite open to Pak...</td>\n",
       "      <td>i be muhajir aur mere lye sab se pehly pakista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>903075788756590593</td>\n",
       "      <td>929467030406758400</td>\n",
       "      <td>[ 0.00511213  0.0066199  -0.00406399 -0.001209...</td>\n",
       "      <td>&lt;User&gt; &lt;User&gt; Doctor Subhash ke PhD in Het Pol...</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; doctor sab sahi me ke phd in hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>881096476616781825</td>\n",
       "      <td>929460995981901825</td>\n",
       "      <td>[-0.6831904   2.609242    2.6378176   2.580363...</td>\n",
       "      <td>After the formation of the government, a singl...</td>\n",
       "      <td>&lt;user&gt; sarkar banne ke bad hindu hit me ek bhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3268145264</td>\n",
       "      <td>929460432498233344</td>\n",
       "      <td>[ 1.6771747   0.14684932 -0.8186511   1.882037...</td>\n",
       "      <td>Hate it when the test is not so frozen</td>\n",
       "      <td>hate it jab test ata ho phr bh acha na ho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>763212669524467712</td>\n",
       "      <td>929459222697431040</td>\n",
       "      <td>[ 1.1214749   3.8859344   3.6560123   2.660346...</td>\n",
       "      <td>&lt;user&gt; One of the victims has been raped and r...</td>\n",
       "      <td>&lt;user&gt; ek dil ek jaan akal ke imitihaan kal kp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label                user               tweet  \\\n",
       "0           0      0          1615850780  929479629840281601   \n",
       "1           1      0  903075788756590593  929467030406758400   \n",
       "2           2      1  881096476616781825  929460995981901825   \n",
       "3           3      1          3268145264  929460432498233344   \n",
       "4           4      0  763212669524467712  929459222697431040   \n",
       "\n",
       "                                                 emb  \\\n",
       "0  [ 0.00447152 -0.00207724 -0.00693714 -0.005786...   \n",
       "1  [ 0.00511213  0.0066199  -0.00406399 -0.001209...   \n",
       "2  [-0.6831904   2.609242    2.6378176   2.580363...   \n",
       "3  [ 1.6771747   0.14684932 -0.8186511   1.882037...   \n",
       "4  [ 1.1214749   3.8859344   3.6560123   2.660346...   \n",
       "\n",
       "                                                text  \\\n",
       "0  I am a young person and I am quite open to Pak...   \n",
       "1  <User> <User> Doctor Subhash ke PhD in Het Pol...   \n",
       "2  After the formation of the government, a singl...   \n",
       "3             Hate it when the test is not so frozen   \n",
       "4  <user> One of the victims has been raped and r...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  i be muhajir aur mere lye sab se pehly pakista...  \n",
       "1  <user> <user> doctor sab sahi me ke phd in hat...  \n",
       "2  <user> sarkar banne ke bad hindu hit me ek bhi...  \n",
       "3          hate it jab test ata ho phr bh acha na ho  \n",
       "4  <user> ek dil ek jaan akal ke imitihaan kal kp...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = tweets['lemmas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3475,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-14c87e0afd07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mSequenceMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhate_lexicons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.85\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mctr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/difflib.py\u001b[0m in \u001b[0;36mratio\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \"\"\"\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtriple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matching_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_calculate_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/difflib.py\u001b[0m in \u001b[0;36mget_matching_blocks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0malo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_longest_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0;31m# a[alo:i] vs b[blo:j] unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;31m# a[i:i+k] same as b[j:j+k]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/difflib.py\u001b[0m in \u001b[0;36mfind_longest_match\u001b[0;34m(self, alo, ahi, blo, bhi)\u001b[0m\n\u001b[1;32m    421\u001b[0m               \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbesti\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbestj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mbesti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbesti\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestsize\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mbesti\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbestsize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mahi\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbestj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbestsize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbhi\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m               \u001b[0;32mnot\u001b[0m \u001b[0misbjunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbestj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbestsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m               \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbesti\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbestsize\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbestj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbestsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_feat = []\n",
    "ctr = 0\n",
    "for sent in sents:\n",
    "#     print(sent)\n",
    "    words = sent.split()\n",
    "    cur_vec = []\n",
    "    for ix in range(len(hate_lexicons)):\n",
    "        temp = False\n",
    "        for word in words:\n",
    "#             print(word)\n",
    "            if word[0]=='p':\n",
    "                continue\n",
    "            if SequenceMatcher(a=hate_lexicons[ix], b=word).ratio()>0.85:\n",
    "                temp = True\n",
    "                ctr += 1\n",
    "        if temp:\n",
    "            cur_vec.append(1)\n",
    "        else:\n",
    "            cur_vec.append(0)\n",
    "    final_feat.append(cur_vec) \n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2195, 1280]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tweets['label'],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_feat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9ed9d0beb796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'final_feat' is not defined"
     ]
    }
   ],
   "source": [
    "final_feat = np.array(final_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(final_feat, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_feat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6f123bb56bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Abuse_Features.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'final_feat' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('Abuse_Features_HEOT.npy',final_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feat = np.load('Abuse_Features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tweets['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = np.load('deepwalk_embs_final.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3475, 209), (3475,), (3475, 64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_feat.shape, labels.shape, embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use = np.concatenate((final_feat,embs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use = final_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3475, 209)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Convolution2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0825 15:35:53.651453 4445287872 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add( Dropout(0.4) )\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 15:35:55.172620 4445287872 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3475, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np_utils.to_categorical(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 15:35:56.397886 4445287872 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0825 15:35:56.403171 4445287872 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0825 15:35:56.449167 4445287872 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0825 15:35:56.459233 4445287872 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0825 15:35:56.536125 4445287872 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0825 15:35:56.689766 4445287872 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2780 samples, validate on 695 samples\n",
      "Epoch 1/40\n",
      "2780/2780 [==============================] - 1s 309us/step - loss: 0.6689 - acc: 0.6180 - val_loss: 0.6446 - val_acc: 0.6619\n",
      "Epoch 2/40\n",
      "2780/2780 [==============================] - 0s 113us/step - loss: 0.6574 - acc: 0.6295 - val_loss: 0.6377 - val_acc: 0.6604\n",
      "Epoch 3/40\n",
      "2780/2780 [==============================] - 0s 130us/step - loss: 0.6538 - acc: 0.6327 - val_loss: 0.6414 - val_acc: 0.6647\n",
      "Epoch 4/40\n",
      "2780/2780 [==============================] - 0s 101us/step - loss: 0.6495 - acc: 0.6399 - val_loss: 0.6499 - val_acc: 0.6561\n",
      "Epoch 5/40\n",
      "2780/2780 [==============================] - 0s 108us/step - loss: 0.6477 - acc: 0.6475 - val_loss: 0.6470 - val_acc: 0.6590\n",
      "Epoch 6/40\n",
      "2780/2780 [==============================] - 0s 125us/step - loss: 0.6446 - acc: 0.6435 - val_loss: 0.6478 - val_acc: 0.6547\n",
      "Epoch 7/40\n",
      "2780/2780 [==============================] - 0s 109us/step - loss: 0.6401 - acc: 0.6500 - val_loss: 0.6574 - val_acc: 0.6446\n",
      "Epoch 8/40\n",
      "2780/2780 [==============================] - 0s 111us/step - loss: 0.6384 - acc: 0.6550 - val_loss: 0.6651 - val_acc: 0.6403\n",
      "Epoch 9/40\n",
      "2780/2780 [==============================] - 0s 125us/step - loss: 0.6381 - acc: 0.6518 - val_loss: 0.6646 - val_acc: 0.6475\n",
      "Epoch 10/40\n",
      "2780/2780 [==============================] - 0s 111us/step - loss: 0.6320 - acc: 0.6565 - val_loss: 0.6755 - val_acc: 0.6374\n",
      "Epoch 11/40\n",
      "2780/2780 [==============================] - 0s 93us/step - loss: 0.6320 - acc: 0.6604 - val_loss: 0.6743 - val_acc: 0.6460\n",
      "Epoch 12/40\n",
      "2780/2780 [==============================] - 0s 108us/step - loss: 0.6280 - acc: 0.6561 - val_loss: 0.6908 - val_acc: 0.6388\n",
      "Epoch 13/40\n",
      "2780/2780 [==============================] - 0s 134us/step - loss: 0.6257 - acc: 0.6579 - val_loss: 0.6948 - val_acc: 0.6417\n",
      "Epoch 14/40\n",
      "2780/2780 [==============================] - 0s 145us/step - loss: 0.6245 - acc: 0.6576 - val_loss: 0.7082 - val_acc: 0.6201\n",
      "Epoch 15/40\n",
      "2780/2780 [==============================] - 0s 112us/step - loss: 0.6243 - acc: 0.6619 - val_loss: 0.7004 - val_acc: 0.6432\n",
      "Epoch 16/40\n",
      "2780/2780 [==============================] - 0s 109us/step - loss: 0.6189 - acc: 0.6647 - val_loss: 0.7061 - val_acc: 0.6475\n",
      "Epoch 17/40\n",
      "2780/2780 [==============================] - 0s 128us/step - loss: 0.6181 - acc: 0.6637 - val_loss: 0.7277 - val_acc: 0.6360\n",
      "Epoch 18/40\n",
      "2780/2780 [==============================] - 0s 126us/step - loss: 0.6177 - acc: 0.6612 - val_loss: 0.7288 - val_acc: 0.6475\n",
      "Epoch 19/40\n",
      "2780/2780 [==============================] - 0s 110us/step - loss: 0.6153 - acc: 0.6601 - val_loss: 0.7418 - val_acc: 0.6360\n",
      "Epoch 20/40\n",
      "2780/2780 [==============================] - 0s 110us/step - loss: 0.6165 - acc: 0.6615 - val_loss: 0.7288 - val_acc: 0.6475\n",
      "Epoch 21/40\n",
      "2780/2780 [==============================] - 0s 111us/step - loss: 0.6148 - acc: 0.6594 - val_loss: 0.7462 - val_acc: 0.6475\n",
      "Epoch 22/40\n",
      "2780/2780 [==============================] - 0s 137us/step - loss: 0.6136 - acc: 0.6615 - val_loss: 0.7408 - val_acc: 0.6489\n",
      "Epoch 23/40\n",
      "2780/2780 [==============================] - 0s 121us/step - loss: 0.6107 - acc: 0.6651 - val_loss: 0.7523 - val_acc: 0.6489\n",
      "Epoch 24/40\n",
      "2780/2780 [==============================] - 0s 147us/step - loss: 0.6117 - acc: 0.6608 - val_loss: 0.7531 - val_acc: 0.6475\n",
      "Epoch 25/40\n",
      "2780/2780 [==============================] - 0s 120us/step - loss: 0.6114 - acc: 0.6629 - val_loss: 0.7671 - val_acc: 0.6245\n",
      "Epoch 26/40\n",
      "2780/2780 [==============================] - 0s 98us/step - loss: 0.6089 - acc: 0.6644 - val_loss: 0.7651 - val_acc: 0.6489\n",
      "Epoch 27/40\n",
      "2780/2780 [==============================] - 1s 190us/step - loss: 0.6087 - acc: 0.6651 - val_loss: 0.7773 - val_acc: 0.6446\n",
      "Epoch 28/40\n",
      "2780/2780 [==============================] - 0s 154us/step - loss: 0.6101 - acc: 0.6651 - val_loss: 0.7807 - val_acc: 0.6432\n",
      "Epoch 29/40\n",
      "2780/2780 [==============================] - 0s 167us/step - loss: 0.6102 - acc: 0.6576 - val_loss: 0.7813 - val_acc: 0.6460\n",
      "Epoch 30/40\n",
      "2780/2780 [==============================] - 0s 141us/step - loss: 0.6056 - acc: 0.6644 - val_loss: 0.7991 - val_acc: 0.6504\n",
      "Epoch 31/40\n",
      "2780/2780 [==============================] - 0s 137us/step - loss: 0.6060 - acc: 0.6655 - val_loss: 0.8027 - val_acc: 0.6317\n",
      "Epoch 32/40\n",
      "2780/2780 [==============================] - 0s 179us/step - loss: 0.6050 - acc: 0.6655 - val_loss: 0.8018 - val_acc: 0.6432\n",
      "Epoch 33/40\n",
      "2780/2780 [==============================] - 0s 127us/step - loss: 0.6055 - acc: 0.6658 - val_loss: 0.8083 - val_acc: 0.6504\n",
      "Epoch 34/40\n",
      "2780/2780 [==============================] - 0s 138us/step - loss: 0.6047 - acc: 0.6665 - val_loss: 0.8081 - val_acc: 0.6489\n",
      "Epoch 35/40\n",
      "2780/2780 [==============================] - 0s 104us/step - loss: 0.6067 - acc: 0.6629 - val_loss: 0.8131 - val_acc: 0.6317\n",
      "Epoch 36/40\n",
      "2780/2780 [==============================] - 0s 144us/step - loss: 0.6038 - acc: 0.6662 - val_loss: 0.8243 - val_acc: 0.6460\n",
      "Epoch 37/40\n",
      "2780/2780 [==============================] - 0s 147us/step - loss: 0.6043 - acc: 0.6640 - val_loss: 0.8213 - val_acc: 0.6460\n",
      "Epoch 38/40\n",
      "2780/2780 [==============================] - 0s 127us/step - loss: 0.6040 - acc: 0.6673 - val_loss: 0.8266 - val_acc: 0.6432\n",
      "Epoch 39/40\n",
      "2780/2780 [==============================] - 0s 120us/step - loss: 0.6040 - acc: 0.6655 - val_loss: 0.8317 - val_acc: 0.6446\n",
      "Epoch 40/40\n",
      "2780/2780 [==============================] - 0s 160us/step - loss: 0.6040 - acc: 0.6669 - val_loss: 0.8379 - val_acc: 0.6460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1304b0190>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( to_use, labels, validation_split=0.2, shuffle=True, epochs=40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = model.predict(to_use[3000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = pred_val.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = labels[3000:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame()\n",
    "final['true'] = true.astype(int)\n",
    "final['pred'] = pred_val.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.78       323\n",
      "           1       0.37      0.11      0.17       152\n",
      "\n",
      "    accuracy                           0.65       475\n",
      "   macro avg       0.53      0.51      0.48       475\n",
      "weighted avg       0.58      0.65      0.59       475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(final['true'],final['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-894024636c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtsne_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \"\"\"\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    811\u001b[0m                           \u001b[0mX_embedded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m                           \u001b[0mneighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m                           skip_num_points=skip_num_points)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     def _tsne(self, P, degrees_of_freedom, n_samples, X_embedded,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0mP\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_exaggeration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         params, kl_divergence, it = _gradient_descent(obj_func, params,\n\u001b[0;32m--> 849\u001b[0;31m                                                       **opt_args)\n\u001b[0m\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             print(\"[t-SNE] KL divergence after %d iterations with early \"\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compute_error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error)\u001b[0m\n\u001b[1;32m    256\u001b[0m                                       \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                       \u001b[0mdof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                                       compute_error=compute_error)\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500)\n",
    "new_values = tsne_model.fit_transform(to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for value in new_values:\n",
    "    x.append(value[0])\n",
    "    y.append(value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red','green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "plt.figure(figsize=(8, 8)) \n",
    "plt.scatter(x, y, c=labels[:,1], cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()\n",
    "train_df['content'] = sents\n",
    "train_df['class'] = tweets['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i be muhajir aur mere lye sab se pehly pakista...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; doctor sab sahi me ke phd in hat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;user&gt; sarkar banne ke bad hindu hit me ek bhi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hate it jab test ata ho phr bh acha na ho</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;user&gt; ek dil ek jaan akal ke imitihaan kal kp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  class\n",
       "0  i be muhajir aur mere lye sab se pehly pakista...      0\n",
       "1  <user> <user> doctor sab sahi me ke phd in hat...      0\n",
       "2  <user> sarkar banne ke bad hindu hit me ek bhi...      1\n",
       "3          hate it jab test ata ho phr bh acha na ho      1\n",
       "4  <user> ek dil ek jaan akal ke imitihaan kal kp...      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils import np_utils\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.models import Model,load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction import text as sktext\n",
    "from sklearn import preprocessing as skp\n",
    "from keras import callbacks as kc\n",
    "from keras import optimizers as ko\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.engine import Layer\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.initializers import Constant\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data phrase length distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x132073250>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training data phrase length distribution\")\n",
    "sns.distplot(train_df['content'].map(lambda ele: len(ele)), kde_kws={\"label\": \"train\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent sentence length in training:\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "print('Most frequent sentence length in training:')\n",
    "lens = train_df['content'].map(lambda ele: len(ele))\n",
    "counts = np.bincount(lens)\n",
    "print(np.argmax(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data phrase length distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13217d910>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Testing data phrase length distribution\")\n",
    "sns.distplot(train_df['content'].map(lambda ele: len(ele)), kde_kws={\"label\": \"test\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = train_df[3000:]\n",
    "train_df = train_df[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data phrase length distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13235c850>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Testing data phrase length distribution\")\n",
    "sns.distplot(test_df['content'].map(lambda ele: len(ele)), kde_kws={\"label\": \"test\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent sentence length in testing:\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "print('Most frequent sentence length in testing:')\n",
    "lens = test_df['content'].map(lambda ele: len(ele))\n",
    "counts = np.bincount(lens)\n",
    "print(np.argmax(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"' + '\\&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## A dictionary to map the punctuations present in the text to relevant strings or symbols\n",
    "punct_mapping = {\"\": \"'\", \n",
    "                 \"\": \"e\", \n",
    "                 \"\": \"'\", \n",
    "                 \"\": \"\", \n",
    "                 \"\": \"e\", \n",
    "                 \"\": \"tm\",\n",
    "                 \"\": \" sqrt \",\n",
    "                 \"\": \"x\",\n",
    "                 \"\": \"2\",\n",
    "                 \"\": \"-\",\n",
    "                 \"\": \"-\",\n",
    "                 \"\": \"'\",\n",
    "                 \"_\": \"-\",\n",
    "                 \"`\": \"'\",\n",
    "                 '': '\"',\n",
    "                 '': '\"',\n",
    "                 '': '\"',\n",
    "                 \"\": \"e\",\n",
    "                 '': 'infinity',\n",
    "                 '': 'theta',\n",
    "                 '': '/',\n",
    "                 '': 'alpha',\n",
    "                 '': '.',\n",
    "                 '': 'a',\n",
    "                 '': '-',\n",
    "                 '': 'beta',\n",
    "                 '': '',\n",
    "                 '': '3',\n",
    "                 '': 'pi',\n",
    "                 ',':'',\n",
    "                 '.':'',\n",
    "                 ':':'',\n",
    "                 '(':'',\n",
    "                 ')':'',\n",
    "                 '*':'',\n",
    "                '\"':'',\n",
    "                '<':'',\n",
    "                '>':''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown_punct(embed, punct):\n",
    "    unknown = ''\n",
    "    for p in punct:\n",
    "        if p not in embed:\n",
    "            unknown += p\n",
    "            unknown += ' '\n",
    "    return unknown\n",
    "\n",
    "## Function to remove special characters from the sentences (if any present)\n",
    "def clean_special_chars(text, punct, mapping):\n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '': ' ... ', '\\ufeff': '', '': '', '': ''}  # Other special characters that I have to deal with in last\n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:, 'content'] = train_df['content'].map(lambda text: clean_special_chars(text, punct, punct_mapping))\n",
    "test_df.loc[:, 'content'] = test_df['content'].map(lambda text: clean_special_chars(text, punct, punct_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                   \"this's\": \"this is\",\n",
    "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "                       \"here's\": \"here is\",\n",
    "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_contractions(text, mapping):\n",
    "    specials = [\"\", \"\", \"\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:, 'content'] = train_df['content'].map(lambda text: clean_contractions(text, contraction_mapping))\n",
    "test_df.loc[:, 'content'] = test_df['content'].map(lambda text: clean_contractions(text, contraction_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:, 'content'] = train_df['content'].map(lambda text: text.lower())\n",
    "test_df.loc[:, 'content'] = test_df['content'].map(lambda text: text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df.values\n",
    "data_test = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,) (3000,) (475,) (475,)\n",
      "-------------------------\n",
      "user user eakdam sahi kha pta nahi kab hate ghi aesa soch kab badle gha yaha ka mohal aakhir kabtak sach se bage ghe 0\n",
      "i be muhajir aur mere lye sab se pehly pakistan he agr ten lakh altaf jese leaders bh be zameen ki behurmati kren un sbko sar e aam phansi deni chahye proud to be a hashtag and hashtag 0\n"
     ]
    }
   ],
   "source": [
    "X_train = data[:,0]\n",
    "Y_train = data[:,1]\n",
    "\n",
    "X_test = data_test[:,0]\n",
    "Y_test = data_test[:,1]\n",
    "\n",
    "print (X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "print (\"-------------------------\")\n",
    "print (X_test[0], Y_test[0])\n",
    "print (X_train[0], Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(\"[a-zA-Z]+\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(X_train.shape[0]):\n",
    "    X_train[ix] = tokenizer.tokenize(X_train[ix])\n",
    "    X_train[ix] = [lemmatizer.lemmatize(i) for i in X_train[ix]]\n",
    "    \n",
    "for ix in range(X_test.shape[0]):\n",
    "    X_test[ix] = tokenizer.tokenize(X_test[ix])\n",
    "    X_test[ix] = [lemmatizer.lemmatize(i) for i in X_test[ix]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3000/3000 [00:00<00:00, 79442.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:\n",
      "11253\n",
      "Maximum length of sentence:\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_words = set()\n",
    "len_max = 0\n",
    "\n",
    "for sent in tqdm(X_train):\n",
    "    \n",
    "    unique_words.update(sent)\n",
    "    \n",
    "    if(len_max<len(sent)):\n",
    "        len_max = len(sent)\n",
    "        \n",
    "## Length of the list of unique_words gives the no of unique words\n",
    "print(\"Vocabulary Size:\")\n",
    "print(len(list(unique_words)))\n",
    "print(\"Maximum length of sentence:\")\n",
    "print(len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_max = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 60) (475, 60)\n"
     ]
    }
   ],
   "source": [
    "tokenizer_keras = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer_keras.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer_keras.texts_to_sequences(X_train)\n",
    "X_test = tokenizer_keras.texts_to_sequences(X_test)\n",
    "\n",
    "## Padding done to equalize the lengths of all input reviews. LSTM networks needs all inputs to be same length.\n",
    "## Therefore reviews lesser than max length will be made equal using extra zeros at end. This is padding.\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./glove.6B.200d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(list(unique_words))\n",
    "embedding_matrix = np.zeros((vocab_size+1, 200))\n",
    "for word, i in tokenizer_keras.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulry Size:\n",
      "11253\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulry Size:\")\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 200\n",
    "max_features = vocab_size + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 60, 300)           3375900   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 60, 256)           439296    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 60, 256)           394240    \n",
      "_________________________________________________________________\n",
      "attention_2 (Attention)      (None, 256)               316       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 4,235,654\n",
      "Trainable params: 4,235,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_acc', patience = 10)\n",
    "callback = [early_stopping]\n",
    "\n",
    "#Model using Keras LSTM\n",
    "model=Sequential()\n",
    "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
    "model.add(Bidirectional(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True)))\n",
    "model.add(Attention(60))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.005),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=ModelCheckpoint('model_self_embedding_final.h5',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = model.layers[-2].output\n",
    "# dense2 = Dense(300, activation='relu', name='layer_2')(output1)\n",
    "input4 = Input(shape=(209,))\n",
    "dense3 = Dense(50, activation='relu', name='layer_3')(input4)\n",
    "merged = concatenate([output1, dense3])\n",
    "pre_final = Dense(50, activation='relu', name='pre_final')(merged)\n",
    "output = layers.Dense(2, activation=\"softmax\", name=\"softmax_layer0\")(pre_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fin = Model(inputs = [model.input, input4], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = np.concatenate((X_train, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_full = np.concatenate((Y_train, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3127 samples, validate on 348 samples\n",
      "Epoch 1/20\n",
      "3127/3127 [==============================] - 58s 18ms/step - loss: 0.6713 - sparse_categorical_accuracy: 0.6134 - val_loss: 0.6312 - val_sparse_categorical_accuracy: 0.6782\n",
      "\n",
      "Epoch 00001: val_sparse_categorical_accuracy improved from -inf to 0.67816, saving model to comb_model.hdf5\n",
      "Epoch 2/20\n",
      "3127/3127 [==============================] - 47s 15ms/step - loss: 0.6605 - sparse_categorical_accuracy: 0.6278 - val_loss: 0.6204 - val_sparse_categorical_accuracy: 0.6782\n",
      "\n",
      "Epoch 00002: val_sparse_categorical_accuracy did not improve from 0.67816\n",
      "Epoch 3/20\n",
      "3127/3127 [==============================] - 44s 14ms/step - loss: 0.6211 - sparse_categorical_accuracy: 0.6537 - val_loss: 0.9202 - val_sparse_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00003: val_sparse_categorical_accuracy did not improve from 0.67816\n",
      "Epoch 4/20\n",
      "3127/3127 [==============================] - 45s 14ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7618 - val_loss: 0.7353 - val_sparse_categorical_accuracy: 0.6552\n",
      "\n",
      "Epoch 00004: val_sparse_categorical_accuracy did not improve from 0.67816\n",
      "Epoch 5/20\n",
      "3127/3127 [==============================] - 44s 14ms/step - loss: 0.3373 - sparse_categorical_accuracy: 0.8753 - val_loss: 0.7920 - val_sparse_categorical_accuracy: 0.5603\n",
      "\n",
      "Epoch 00005: val_sparse_categorical_accuracy did not improve from 0.67816\n",
      "Epoch 6/20\n",
      "3127/3127 [==============================] - 44s 14ms/step - loss: 0.2234 - sparse_categorical_accuracy: 0.9309 - val_loss: 1.1249 - val_sparse_categorical_accuracy: 0.6293\n",
      "\n",
      "Epoch 00006: val_sparse_categorical_accuracy did not improve from 0.67816\n",
      "Epoch 7/20\n",
      "3127/3127 [==============================] - 45s 14ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9655 - val_loss: 1.7221 - val_sparse_categorical_accuracy: 0.6437\n",
      "\n",
      "Epoch 00007: val_sparse_categorical_accuracy did not improve from 0.67816\n",
      "Epoch 8/20\n",
      "3127/3127 [==============================] - 44s 14ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9824 - val_loss: 1.8394 - val_sparse_categorical_accuracy: 0.6006\n",
      "\n",
      "Epoch 00008: val_sparse_categorical_accuracy did not improve from 0.67816\n",
      "Epoch 9/20\n",
      "3127/3127 [==============================] - 44s 14ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9869 - val_loss: 2.0887 - val_sparse_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00009: val_sparse_categorical_accuracy did not improve from 0.67816\n",
      "Epoch 10/20\n",
      "3127/3127 [==============================] - 45s 14ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.9936 - val_loss: 2.6335 - val_sparse_categorical_accuracy: 0.5431\n",
      "\n",
      "Epoch 00010: val_sparse_categorical_accuracy did not improve from 0.67816\n",
      "Epoch 11/20\n",
      "3127/3127 [==============================] - 45s 14ms/step - loss: 0.0241 - sparse_categorical_accuracy: 0.9946 - val_loss: 2.4523 - val_sparse_categorical_accuracy: 0.5920\n",
      "\n",
      "Epoch 00011: val_sparse_categorical_accuracy did not improve from 0.67816\n"
     ]
    }
   ],
   "source": [
    "adam = ko.Nadam()\n",
    "model_fin.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",])\n",
    "\n",
    "file_path = \"comb_model.hdf5\"\n",
    "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_sparse_categorical_accuracy\", verbose = 1, save_best_only = True, mode = \"max\")\n",
    "early_stop = kc.EarlyStopping(monitor = \"val_sparse_categorical_accuracy\", mode = \"max\", patience=10)\n",
    "history = model_fin.fit([X_full,to_use],Y_full,validation_split=0.1, batch_size=500, epochs=20, callbacks = [check_point, early_stop])\n",
    "\n",
    "# histories.append(np.max(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n",
    "# iterations.append(np.argmax(np.asarray(history.history['val_sparse_categorical_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fin.load_weights('comb_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = model_fin.predict([X_test, to_use[3000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = pred_val.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = data_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame()\n",
    "final['true'] = true.astype(int)\n",
    "final['pred'] = pred_val.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7880597 , 0.49285714])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(final['true'],final['pred'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       323\n",
      "           1       0.54      0.45      0.49       152\n",
      "\n",
      "    accuracy                           0.70       475\n",
      "   macro avg       0.65      0.64      0.64       475\n",
      "weighted avg       0.69      0.70      0.69       475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(final['true'], final['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = ['modi accha kaam kar raha hai', 'rahul gandhi ko kuch nhi aata', 'mera naam dhoni hai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tweets = ['modi is doing well', 'rahul gandhi knows nothing', 'my name is dhoni']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_check = ['he is a hidje hindu','he is a hidje muslim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(len(x_check)):\n",
    "    x_check[ix] = tokenizer.tokenize(x_check[ix])\n",
    "    x_check[ix] = [lemmatizer.lemmatize(i) for i in x_check[ix]]\n",
    "    \n",
    "x_check = tokenizer_keras.texts_to_sequences(x_check)\n",
    "x_check = sequence.pad_sequences(x_check, maxlen=len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3475, 209)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = model_fin.predict([x_check, np.zeros((2, 209))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9978238e-01, 2.1762180e-04],\n",
       "       [9.9978369e-01, 2.1626591e-04]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
